{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c745bc",
   "metadata": {},
   "source": [
    "# American Sign Language (ASL) Final Project W251 <br>Detectron2 Custom Dataset\n",
    "___\n",
    "\n",
    "Adapted from Roboflow Collab located [here](https://colab.research.google.com/drive/1-TNOcPm3Jr3fOJG8rnGT9gh60mHUsvaW#scrollTo=kc8MmgZugZWR).\n",
    "\n",
    "Used on a `g4dn.2xlarge` AWS EC2 Instance with Nvidia Deep Learning AMI installed and within a Nvidia docker container `nvcr.io/nvidia/pytorch:21.09-py3`\n",
    "\n",
    "Command Line Scripts Executed:\n",
    "\n",
    "```shell\n",
    "docker run --net=host --gpus=all --ipc=host -v ~/data:/data -p 8882:8888 -ti nvcr.io/nvidia/pytorch:21.09-py3 bash\n",
    "jupyter lab --no-browser --ip=0.0.0.0 --allow-root\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c6904f",
   "metadata": {},
   "source": [
    "#### 1. Download Detectron Repository and any dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc424e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### install dependencies\n",
    "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
    "!pip install cython pyyaml==5.1\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "\n",
    "!apt-get update # make sure system is updated and install python3-opencv\n",
    "!DEBIAN_FRONTEND=noninteractive apt-get install -y python3-opencv\n",
    "\n",
    "#### install model\n",
    "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch, torchvision\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# standard libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "# Training \n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33fbddb",
   "metadata": {},
   "source": [
    "#### 2. Download Images in COCO format from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://app.roboflow.com/ds/QLy1EzrO08?key=OSNpEWnqN6\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcea47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"my_dataset_train\", {}, \"train/_annotations.coco.json\", \"train\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"valid/_annotations.coco.json\", \"valid\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"test/_annotations.coco.json\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6da05",
   "metadata": {},
   "source": [
    "#### 3. Train model using detectron packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training module to use coco validation during training\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56145d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 1500 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 36 #your number of classes + 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ae276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20022d52",
   "metadata": {},
   "source": [
    "#### 4. Save a Pytorch model by saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c27ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ./output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dae28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"my_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/NVIDIA-AI-IOT/torch2trt\n",
    "# %cd torch2trt\n",
    "# !python setup.py install\n",
    "%!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4da46",
   "metadata": {},
   "source": [
    "#### 5. Convert Model to Tensorrt\n",
    "(Currently not possible onnx.optimizer module used to convert to ONNX is not available and torch2trt does not work with the input format for this model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6466969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import detectron2\n",
    "# import onnx\n",
    "# import cv2\n",
    "\n",
    "# # import some common detectron2 utilities\n",
    "# from detectron2 import model_zoo\n",
    "# from detectron2.config import get_cfg\n",
    "# #from detectron2.export import export_onnx_model, export_caffe2_model\n",
    "# from detectron2.modeling import build_model\n",
    "# from detectron2.checkpoint import DetectionCheckpointer\n",
    "# import detectron2.data.transforms as T\n",
    "# import torch\n",
    "# from torch2trt import torch2trt\n",
    "# import timm\n",
    "# import time\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1334366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = cv2.imread('train/0-0_jpg.rf.6267a69264abb1ca2948505799de1968.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a6c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92e26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6528a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg2 = get_cfg()\n",
    "# # add project-specific config \n",
    "# cfg2.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# # Find a model from detectron2's model zoo.\n",
    "# cfg2.MODEL.WEIGHTS = \"output/model_final.pth\"\n",
    "# # cfg.MODEL.DEVICE='cpu'\n",
    "\n",
    "# # Build model and prepare input\n",
    "# model = build_model(cfg2)\n",
    "# model.eval()\n",
    "# checkpointer = DetectionCheckpointer(model)\n",
    "# checkpointer.load(cfg2.MODEL.WEIGHTS)\n",
    "# aug = T.ResizeShortestEdge([cfg2.INPUT.MIN_SIZE_TEST, cfg2.INPUT.MIN_SIZE_TEST],\n",
    "#                            cfg2.INPUT.MAX_SIZE_TEST)\n",
    "\n",
    "# height, width = im.shape[:2]\n",
    "# image = aug.get_transform(im).apply_image(im)\n",
    "# image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "# inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "# image.size()\n",
    "\n",
    "\n",
    "\n",
    "# inputs = [{\"image\": image}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28daea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall onnx\n",
    "# !pip install git+git://github.com/onnx/onnx.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a8b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "\n",
    "# dummy_input = torch.randn(800, 800, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031eedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch_out = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4489cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12efc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import detectron2.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474879bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install  onnxoptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21abd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exported_model = export_caffe2_tracing(cfg2, model, [inputs], output_folder = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed836a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Onnx model export_onnx_model\n",
    "# onnxModel = export_onnx_model(cfg2, model, [inputs])\n",
    "# onnx.save(onnxModel, \"/data/detectron2_final.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
